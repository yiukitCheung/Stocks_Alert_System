{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import kernels\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model (Gaussian Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_score(df):\n",
    "\n",
    "    X = df.copy()\n",
    "    X = X.drop(['timestamp'], axis=1)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    X_train = X[:train_size].drop('close', axis=1)\n",
    "    y_train_data = X['close'][:train_size]\n",
    "    X_test = X[train_size:].drop('close', axis=1)\n",
    "    y_test_data = X['close'][train_size:]\n",
    "    \n",
    "    # Train the model\n",
    "    kernel = kernels.RBF()\n",
    "    model = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
    "    model.fit(X_train, y_train_data)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test_data, predictions)\n",
    "    \n",
    "    # Plot predictions and actual stock prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X_test.index, np.expm1(predictions), label='Predictions')\n",
    "    plt.plot(X_test.index, np.expm1(y_test_data), label='Actual')\n",
    "    plt.title('NVDA Stock Price Predictions - Gaussian Process')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "  def __init__(self, dataframe, window_size):\n",
    "\n",
    "    self.window_size = window_size\n",
    "    \n",
    "    # Convert dataframe to tensors\n",
    "    features = torch.tensor(dataframe.drop(['close'],axis=1).values, dtype=torch.float32)\n",
    "    targets = torch.tensor(dataframe['close'].values, dtype=torch.float32)\n",
    "\n",
    "    self.windows = []\n",
    "    self.targets = []\n",
    "    \n",
    "    # Genearate windows\n",
    "    max_num_windows = len(features) - self.window_size \n",
    "    \n",
    "    for i in range(max_num_windows):\n",
    "      \n",
    "      # Extract window data and target\n",
    "      window_data_tensor = features[i:i + self.window_size]\n",
    "      target = targets[i + self.window_size] # Predict the next day's close price\n",
    "      \n",
    "      # Append to the list\n",
    "      self.windows.append(window_data_tensor)\n",
    "      self.targets.append(target)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.windows)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if idx >= len(self.windows):\n",
    "      raise IndexError(\"Index out of range\")\n",
    "    return self.windows[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, d_model, dropout=0.1, max_len=256):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    pe = torch.zeros(max_len, d_model)\n",
    "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "    self.register_buffer('pe', pe)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.pe[:x.size(0), :]\n",
    "    return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "  def __init__(self, input_dim, d_model, nhead, num_encoder_layers,\n",
    "                num_decoder_layers, dim_feedforward, dropout):\n",
    "\n",
    "    super(TransformerModel, self).__init__()\n",
    "    self.linear_encoder = nn.Linear(input_dim, d_model)\n",
    "    self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "    self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "    self.ffn = nn.Sequential(\n",
    "      nn.Linear(d_model, dim_feedforward),\n",
    "      nn.BatchNorm1d(dim_feedforward),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(dim_feedforward, d_model),\n",
    "      nn.BatchNorm1d(d_model),\n",
    "      nn.ReLU())\n",
    "    self.linear_decoder = nn.Linear(d_model, 1)\n",
    "    self.d_model = d_model\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Validate h3_indices\n",
    "        \n",
    "    # Encode the input features\n",
    "    x = self.linear_encoder(x) * math.sqrt(self.d_model)\n",
    "    # Add positional encoding to input features\n",
    "    x = self.pos_encoder(x)\n",
    "    # Transformer expects inputs in the shape (S, N, E) -> (sequence_length, batch_size, d_model)\n",
    "    x = x.transpose(0, 1)\n",
    "    # Pass through the transformer\n",
    "    transformer_output = self.transformer(x, x)\n",
    "\n",
    "    # Apply feedforward network with BatchNorm1d\n",
    "    batch_size, seq_len, feature_dim = transformer_output.size()\n",
    "    transformer_output = transformer_output.contiguous().view(-1, feature_dim)\n",
    "    # Apply feedforward network\n",
    "    transformer_output = self.ffn(transformer_output)\n",
    "    # Use the last time step for each sequence in the batch\n",
    "    transformer_output = transformer_output.view(seq_len, batch_size, self.d_model).transpose(0, 1).contiguous()\n",
    "    output = self.linear_decoder(transformer_output[-1])\n",
    "    return output.squeeze(1)\n",
    "\n",
    "def init_weights(m):\n",
    "  if type(m) in [nn.Linear, nn.Conv2d]:\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    if m.bias is not None:\n",
    "      nn.init.zeros_(m.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTrainer:\n",
    "    def __init__(self, model, epochs, criterion, optimizer, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model (torch.nn.Module): The PyTorch model to train.\n",
    "            epochs (int): Number of epochs to train.\n",
    "            criterion (torch.nn.Module): The loss function.\n",
    "            optimizer (torch.optim.Optimizer): The optimizer.\n",
    "            scheduler (optional): Learning rate scheduler (if any).\n",
    "        \"\"\"\n",
    "        self.l1_lambda = 0.001\n",
    "        self.l2_lambda = 0.001\n",
    "        \n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.verbose = verbose\n",
    "        self.model_path = '/Users/yiukitcheung/Documents/Projects/Stocks/models/'\n",
    "        \n",
    "    def train(self, train_dataloader, epoch, device):\n",
    "        self.model.train()\n",
    "\n",
    "        # Initialize accumulators\n",
    "        total_loss = 0\n",
    "        train_pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader),\n",
    "                        desc=f\"Epoch {epoch + 1}/{self.epochs}\")\n",
    "\n",
    "        # Train over batches\n",
    "        for _, (x_batch, y_batch) in train_pbar:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Predict\n",
    "            y_pred = self.model(x_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            # Calculate regularization terms\n",
    "            l1_regularization = torch.tensor(0.).to(device)\n",
    "            l2_regularization = torch.tensor(0.).to(device)\n",
    "            for param in self.model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = self.criterion(y_pred, y_batch) + self.l1_lambda * l1_regularization + self.l2_lambda * l2_regularization\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'Batch Loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "        # Calculate average loss\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        return avg_train_loss\n",
    "\n",
    "    def validate(self, test_dataloader, device):\n",
    "        self.model.eval()\n",
    "\n",
    "        # Initialize accumulators\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader, desc=\"Validating\"):\n",
    "                x_batch, y_batch = batch\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                # Predict\n",
    "                y_pred = self.model(x_batch)\n",
    "\n",
    "                # Compute loss\n",
    "                batch_loss = self.criterion(y_pred, y_batch)\n",
    "                total_loss += batch_loss.item()\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_val_loss = total_loss / len(test_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "        return avg_val_loss\n",
    "\n",
    "    def run(self, df, window_size, batch_size, device):\n",
    "        \"\"\"\n",
    "        Run the training and validation over multiple folds.\n",
    "        Args:\n",
    "            df (pd.DataFrame): Dataframe containing the data.\n",
    "            window_size (int): The size of the sliding window.\n",
    "            batch_size (int): Batch size for dataloaders.\n",
    "            device (torch.device): The device to train on.\n",
    "        \"\"\"\n",
    "        tscv = TimeSeriesSplit(n_splits=4)\n",
    "        folds_val_results = {}\n",
    "        folds_train_results = {}\n",
    "\n",
    "        # Expanding Window Cross-Validation Folds\n",
    "        for fold, (train_index, val_index) in enumerate(tscv.split(df)):\n",
    "            train_df = df.iloc[train_index]\n",
    "            val_df = df.iloc[val_index]\n",
    "\n",
    "            # Create datasets and dataloaders\n",
    "            train_dataset = TimeSeriesDataset(train_df, window_size=window_size)\n",
    "            val_dataset = TimeSeriesDataset(val_df, window_size=window_size)\n",
    "\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "            val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Initialize results containers for each fold\n",
    "            fold_val_results = []\n",
    "            fold_train_results = []\n",
    "\n",
    "            # Train and validate for each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                avg_train_loss = self.train(train_dataloader, epoch, device)\n",
    "                avg_val_loss = self.validate(val_dataloader, device)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"Fold {fold+1}: Epoch [{epoch + 1}/{self.epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "                    print(f\"Fold {fold+1}: Epoch [{epoch + 1}/{self.epochs}], Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "                # Record validation and training loss\n",
    "                fold_val_results.append(avg_val_loss)\n",
    "                fold_train_results.append(avg_train_loss)\n",
    "\n",
    "            # Store results for each fold\n",
    "            folds_val_results[fold] = fold_val_results\n",
    "            folds_train_results[fold] = fold_train_results\n",
    "\n",
    "        # Store the model\n",
    "        self.save_model()\n",
    "        \n",
    "        return folds_train_results, folds_val_results\n",
    "    \n",
    "    def save_model(self):\n",
    "        save_path = os.path.join(self.model_path+'_NVDA.pth')\n",
    "        torch.save(self.model.state_dict(),save_path)\n",
    "    \n",
    "    def viz_performance(self, train, eval):\n",
    "        # Assuming folds_train_results and folds_val_results are populated as in your example\n",
    "        # Create a new figure\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Define a limited set of contrasting colors\n",
    "        colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "        # Number of folds\n",
    "        folds = len(train)\n",
    "\n",
    "        # Plot each fold\n",
    "        for i in range(folds):\n",
    "            color = colors[i // 4]  # Cycle through colors every 4 folds\n",
    "            epochs = np.arange(i * len(train[i]), (i + 1) * len(train[i]))\n",
    "            \n",
    "            fig.add_trace(go.Scatter(x=epochs, y=train[i], mode='lines', name='Train' if i == 0 else None,\n",
    "                                    line=dict(color=color, dash='solid'), showlegend=(i == 0)))\n",
    "            fig.add_trace(go.Scatter(x=epochs, y=eval[i], mode='lines', name='Eval' if i == 0 else None,\n",
    "                                    line=dict(color=color, dash='dash'), showlegend=(i == 0)))\n",
    "\n",
    "            # Add vertical line to indicate fold boundary\n",
    "            if i < folds - 1:\n",
    "                fig.add_shape(type=\"line\", x0=(i + 1) * len(train[i]) - 0.5,\n",
    "                                y0=min(min(train[i]), min(eval[i])),\n",
    "                                x1=(i + 1) * len(train[i]) - 0.5,\n",
    "                                y1=max(max(train[i]), max(eval[i])),\n",
    "                                line=dict(color=\"black\", dash=\"dash\"))\n",
    "\n",
    "            # Add text annotation to indicate fold number\n",
    "            fig.add_annotation(x=(i + 0.5) * len(train[i]),\n",
    "                                y=max(max(train[i]), max(eval[i])),\n",
    "                                text=f\"Fold {i + 1}\", showarrow=False, yshift=10)\n",
    "\n",
    "        # Add titles and labels\n",
    "        fig.update_layout(\n",
    "            title='Training and Evaluation Metrics',\n",
    "            xaxis_title='Epochs',\n",
    "            yaxis_title='Metric',\n",
    "            legend_title='Legend',\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class test_model:\n",
    "\n",
    "#     def __init__(self,df,model,device):\n",
    "#         self.df = df\n",
    "#         self.model = model\n",
    "#         self.device = device\n",
    "#         self.window_size = 30\n",
    "\n",
    "#     def predict(self):\n",
    "#         test_dataset = TimeSeriesDataset(self.df, window_size=self.window_size)\n",
    "#         test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "#         self.model.eval()        \n",
    "        \n",
    "#         all_pred = []\n",
    "#         all_targets = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(test_dataloader, desc=\"Predicting...\"):\n",
    "#                 inputs, targets = batch\n",
    "#                 inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "#                 # Predict\n",
    "#                 y_pred = self.model(inputs)\n",
    "                \n",
    "#                 # Convert to numpy arrays\n",
    "#                 y_pred = y_pred.cpu().numpy()\n",
    "#                 targets = targets.cpu().numpy()\n",
    "                \n",
    "#                 # Append to the list\n",
    "#                 all_pred.append(y_pred)\n",
    "#                 all_targets.append(targets) \n",
    "            \n",
    "#             # Concatenate all the predictions and targets\n",
    "#             all_pred = np.concatenate(all_pred, axis=0)\n",
    "#             all_targets = np.concatenate(all_targets, axis=0)\n",
    "            \n",
    "#         return all_pred, all_targets\n",
    "    \n",
    "# # Instantiate the prediction model\n",
    "# model = TransformerModel(input_dim = df.shape[1]-1, d_model=64, nhead=4, num_encoder_layers=2,\n",
    "#                         num_decoder_layers=2, dim_feedforward=256, dropout=0.1)\n",
    "\n",
    "# model.load_state_dict(torch.load('/Users/yiukitcheung/Documents/Projects/Stocks/models/_NVDA.pth'))\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# pre_processed_df_test = DataPreprocessor.preprocess(df_test)\n",
    "\n",
    "# # Ensure that the test data has the same columns as the training data\n",
    "# missing_cols = set(df.columns) - set(pre_processed_df_test.columns)\n",
    "\n",
    "# for col in missing_cols:\n",
    "#     pre_processed_df_test[col] = 0\n",
    "\n",
    "# tester = test_model(pre_processed_df_test, model, device)\n",
    "# predictions, targets = tester.predict()\n",
    "# # Plot predictions and actual stock prices for the last 100 days\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(df_test.index[-70:], np.expm1(predictions), label='Predictions')  # Take the last 100 predictions\n",
    "# plt.plot(df_test.index[-70:], np.expm1(targets), label='Actual')       # Take the last 100 actuals\n",
    "# plt.title('NVDA Stock Price Predictions')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Price')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class with the database and collection details\n",
    "prepare_data = StockDataPreprocessor(db_name=\"local\",\n",
    "                                    collection_name=\"technical_stock_data\", \n",
    "                                    symbol=\"NVDA\")\n",
    "\n",
    "# Fetch data from MongoDB\n",
    "prepare_data.fetch_data()\n",
    "# Split the data into training and testing datasets\n",
    "prepare_data.split_data()\n",
    "\n",
    "# Retrieve training and test data\n",
    "train_data = prepare_data.get_train_data()\n",
    "test_data = prepare_data.get_test_data()\n",
    "\n",
    "# Initialize the preprocessor with columns to exclude from log transformation\n",
    "preprocessor = DataPreprocessor(exclude_columns=['MACD', 'MACD_SIGNAL', 'MACD_HIST'])\n",
    "processed_train_data = preprocessor.preprocess(train_data)\n",
    "\n",
    "# Define model, criterion, optimizer, and device\n",
    "\n",
    "# Set device to apple silicon if available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device found.\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerModel(input_dim= processed_train_data.shape[1]-1, d_model=64, nhead=4, num_encoder_layers=2,\n",
    "                        num_decoder_layers=2, dim_feedforward=256, dropout=0.1)\n",
    "\n",
    "# Apply weight initialization                          \n",
    "model.apply(init_weights)\n",
    "\n",
    "# Set model to device\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create the trainer object\n",
    "trainer = TimeSeriesTrainer(model=model, \n",
    "                            epochs=10,\n",
    "                            criterion=criterion,\n",
    "                            optimizer=optimizer,\n",
    "                            verbose=False)\n",
    "\n",
    "# Run training with cross-validation\n",
    "folds_train_results, folds_val_results = trainer.run(df=processed_train_data, \n",
    "                                                    window_size=30, \n",
    "                                                    batch_size=32, \n",
    "                                                    device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
